# 《分布式缓存-原理，架构及Go语言实现》总结

### 🔮前言

这本书讲了关于缓存的一些基础知识，以及如何实现一个简单的分布式缓存。

书里分为三个部分

1. 基本实现
   - 基于HTTP实现
   - 基于REST和TCP协议的混合接口
   - RocksDB实现缓存数据的持久化
2. 性能提升
   - pipeline加速
   - RocksDB批量写入
   - 异步操作
3. 分布式集群
   - 一致性散列实现负载均衡节点
   - 节点再平衡
   - 缓存的生存时间和超时机制



### 💸Part. 1 基础实现

这部分使用golang基础实现一个简单的缓存服务，从Go本身提供的http接口开始开发，实现Set,Get,Del方法，然后基于TCP协议自定义协议进行缓存的处理，最后考虑到内存存储数据容易丢失的问题，再通过RocksDB实现了缓存数据的持久化。

#### 基于HTTP实现

实现步骤：

1. 使用map保存数据
2. 写一个handler处理请求
3. 调用http.ListenAndServez

三种方法：

- SET：将一对key-value设置进缓存服务器，通过HTTP的PUT方法
- GET：查询某个键并获取值，使用HTTP的GET方法
- DEL：从缓存里删除某个键，使用HTTP的DELETE方法

![](http://image.cocoroise.cn/cache-1.png)

这里使用的缓存是内存缓存(in memory)，数据结构如下

```go
type inMemeoryCache struct {
	c  map[string][]byte // 保存键值对
    mutex synv.RWMutex // 对Map的并发访问提供读写锁保护
    Stat // 记录缓存状态
}
```



> Redis：开源的 in memory数据结构。可以用作数据库，缓存和消息代理中间件。支持Lua脚本，LRU缓存淘汰策略，事务处理和两种磁盘持久化方案(RDB和AOF)，还能建立Redis集群。
>
> - RDB：指定时间点把内存数据集快照存入磁盘。如果在这个时间内有写操作，就进行一个写时复制(copy on write)的操作。
> - AOF：把服务端的所有写操作(set和del)记入磁盘的日志文件。服务重新启动的时候，会根据日志重构整个内存映像。



#### 基于REST和TCP协议的混合接口

> ABNF拓展的巴科斯范式，一般用于描述互联网协议。HTTP协议就是以它作为协议的描述范式。

![](http://image.cocoroise.cn/cache-2.png)

与上一章不同之处：

1. 需要创建一个tcp服务监听的goroutine
2. 服务端需要自己监听端口，获取字符流进行处理



#### 缓存数据的持久化

之前实现的两种方式都是把数据保存在内存里的，不仅有内存的限制而且机器一重启数据就会丢失。虽然缓存不像数据库需要持久化，对保存的要求并不是很高，但是这种也是不能够接受的。书里使用了RocksDB来持久化保存缓存，这个库是用c++写的，提供了字节流形式的键值对存储。值得注意的是，优化写入的性能的手段有提高磁盘的写入速度和降低RocksDB的写放大系数(写入操作本身的开销比)。

在这个章节里，由于要使用C++的库，所以需要用到cgo。然后把缓存的数据再写入DB里进行存储就行了。简单的数据结构如下

```go
type rocksdbCache struct{
    db *C.rocksdb_t
    ro *C.rocksdb_readoptions_t
    wo *rocksdb_writeoptions_t
    e *C.char
}
```

> RocksDB使用了一种叫日志直写(write ahead log,WAL)的技术，写入操作不会尽可能块的写入日志里，而是后台另外有线程慢慢的处理日志内容再把它插入静态排序表里。所以有时候看到的数据可能和预料的不太一样。



### 🍯Part.2 性能提升

书里的第二部分专注于提升性能，上一章的简单实现和持久化缓存操作结束后，性能大概能达到redis的一半。这部分通过客户端使用pipelining技术来加速自己的吞吐量，使用RocksDB的批量写入功能来提升缓存Set性能，使用异步操作缓存Get性能，进行这些优化之后，性能大约提升了不止一倍。

#### pipeline加速

pipelinine是一种网络技术，可以把**多个请求**通过**同一个TCP连接**连续不断的发送给服务端，并且不用等待服务端的响应。

但是虽然这种技术可以提高吞吐量和rps，但是请求的平均响应时间却变长了。因为平均响应时间计算的是每个请求从开始到接收完响应之间的时间查，由于服务器在期间需要处理的请求变多了，所以这段时间也变长了。

![](http://image.cocoroise.cn/cache-3.png)

#### RocksDB批量写入

批量写入原理：把服务端收到的Set请求积攒起来，一次性写入磁盘。

好处：

- 把多个小的写操作合并成一个大的写操作，减少了磁盘的寻道时间和旋转延时
- 写入的内容集中，减少了CPU载入内存的次数和cache miss的概率
- Set操作可以尽快返回而不需要等待磁盘操作的结果

缺点：

- 不知道每一次批量Set操作的真实结果
- Set结果返回的时候，键值对不一定进入了缓存

实现方式：

1. 设置一个计数器变量存储批量的大小，每有一个请求就+1，到了这个量就写入RocksDB
2. 设置一个无限的定时器，只要计数器不为空，每到一定时间就写入保存的批量数据



#### 异步操作

原理：当服务端收到请求时，在一个新的goroutine里调用cache.Cache方法，这样原来的goroutine就可以立刻开始处理来自该TCP连接的后续请求。

优点：速度快，高效利用CPU，减少等待的时间

缺点：额外的实现复杂度和时间开销

![](http://image.cocoroise.cn/cache-4.png)

异步操作的副作用：

多个goroutine处理数据然后自行返回的数据可能会互相夹杂，导致客户端完全无法解析其中的内容。服务端承担先进先出的职责还是客户端承担是由协议的设计者决定的。比如HTTP/1.1在处理pipelining的时候就要求服务端承担，HTTP/2则是要求客户端。这里为了演示功能，就定在服务端实现。

解决方法：

使用一个channel来接收所有goroutine发送过来的结果，依次响应发送回客户端。

> Go里的channel是goroutine协程之间通信的管道。所有的channel都关联了一个类型，信道只能运输这种类型的数据，运输其他的数据类型都是非法的。
>
> ```go
> a := make(chan int) // 定义信道 类型是int
> data := <- a // 读取信道 a  
> a <- data // 写入信道 a
> ```

实现原理：

1. 使用channel的channel来接受goroutine的结果，它的底层结构是另外一个channel。
2. 每一个缓存操作gotoutine都会有一个chan *result，这些chan *result被插入resultCh的时机是同步的。所以取的时候只要从resultCh里取下一个就能保证正确的顺序。
3. 用来接受响应的普通channel:ch1,ch2,ch3会按照先进先出的顺序发送给接受channel，这样异步操作的次序就无关紧要了。
4. 接受channel首先收到的是ch1,然后等ch1里的响应数据收到了才去接受ch2，这样接受channel发送出去的数据就是按顺序的。

```go
type result struct {
    v []byte
    e error
}
func (s *Serve) process(conn net.Conn){
    // ...
    resultCh := make(chan chan *result,5000)
} 
```

![](http://image.cocoroise.cn/cache-5.png)

实现之后，把缓存操作都改成了异步的，只要客户端请求密度越高，异步操作带来的性能提升就越大。



### 🔩Part.3 分布式集群

集群：

- 高可用集群(HA)
- 负债均衡集群(load balancing)
- 高性能计算集群(HPC)
- 网格计算

由于缓存服务不涉及计算，所以对缓存服务集群的要求是高可用和负载均衡即可。

**高可用**：当前某个节点失效的情况下，对该节点的访问能转移到其他正常的节点上。而且对某个节点进行离线维护再上线，对整个集群的运行没有影响。

**负债均衡**：通过某种算法，将整体的工作负载均分到每个节点上。

分布式系统采用的协议:

**gossip**: 计算机与计算机之间互相通信的协议，模仿社交网络和传染病的传播方式，以去中心化的思想实现了分布式的一致性。

![](http://image.cocoroise.cn/cache-8.png)

#### 一致性散列实现负载均衡节点

负载应该由哪个节点进行处理需要对键进行一致性散列计算来获得。如果某个服务节点接收到的请求不应该由这个节点进行处理，则该节点会拒绝该请求，并通知客户端正确的节点。

所以客户端在启动的时候会随机访问一台缓存节点，获取所有节点列表并对自己操作的每个键计算一致性散列来决定访问哪个节点。

**一致性散列**：特殊的散列表，每次需要重新分配列表的时候只需要映射的键的平均数只有K/n个，K是键的总数，n是对应的节点数。

普通的散列表的键对应的节点就是由其散列值对节点总数取模决定，所以每当有新的节点加入的时候，大多数键的取模余数也会发生变化，这样的话，访问的缓存节点就不与上次的相同，缓存就失效了。

但是一致性散列使用的是环形的实现方式。节点ID和key都需要进行散列计算，来决定自己在环上的位置。由于计算散列值的函数是由算法决定的，所以不受节点数的影响，如果加入了一个新的节点，影响的也只是某个区间内的部分节点。

![](http://image.cocoroise.cn/cache-6.png)

**虚拟节点**：节点比较少的时候，区间长度可能不平衡，这个时候就需要加入虚拟节点，帮助负债均衡。

![](http://image.cocoroise.cn/cache-7.png)

#### 节点再平衡

扩容的时候，新增节点一开始都是空的，但是老节点都是满的，这个时候就需要节点再平衡，把老节点的一部分缓存迁移到新的节点上。

实现：

1. 加入新节点，用一致性散列找出需要被迁移的键
2. 在老节点进行遍历，把它们复制到对应的新节点
3. 老节点内把复制过的缓存删除

由于遍历这个步骤比较花费资源，所以有些情况下无需运行再平衡，比较建议的情况有：

- 新加入的节点比较多
- 老节点缓存容量已经见顶
- 缓存永不超时

#### 缓存的生存时间和超时机制

设置了缓存的生存时间ttl，节点上的缓存就会过一段时间之后自动删除。这样不仅可以节省硬盘上的资源，还能强制缓存刷新，以免实际存储的资源发生了变化。

实现：

1. 设置一个Int参数保存生存时间
2. 开启一个无限循环，计算值的创建时间，加上生存时间，如果小于当前时间，则把它删除

这样的实现是FIFO的实现，如果每次GET操作的时候更新了缓存的时间，那么就相当于实现了一个最近最少使用策略(LRU)。如果不使用时间而是使用计数器，每次GET的时候就在计数器上加1，那么就是最少使用频率策略(LFU)。



### 📰总结

缓存的实现：拦截http请求，从缓存里拿数据，使用rocksDB持久化

缓存的优化：pipelining，批量写入数据，异步操作，但是要处理副作用

分布式缓存：分布式协议，负债均衡的处理，节点扩容的处理，缓存清理机制
